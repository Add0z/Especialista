# Kafka Ingestion Benchmark: High-Performance CSV to Topic

Este projeto apresenta uma an√°lise de performance e implementa√ß√£o de uma pipeline de ingest√£o massiva de dados, movendo mais de 5,2 milh√µes de registros de um arquivo CSV para o Apache Kafka. O foco principal foi o equil√≠brio entre Throughput (vaz√£o), utiliza√ß√£o de CPU e efici√™ncia de I/O.

## üöÄ Resultados do Benchmark

* **Volume de Dados:** 5.208.181 registros (CSV).
* **Throughput M√°ximo (12 Parti√ß√µes):** **361.002 registros/segundo**.
* **Throughput (6 Parti√ß√µes):** **342.345 registros/segundo**.
* **Tempo Total (12 Parti√ß√µes):** ~14,4 segundos.
* **Tempo Total (6 Parti√ß√µes):** ~15,2 segundos.
* **Stack:** Java 21, Spring Boot 3.x, Apache Kafka.

---

## üß† Decis√µes Arquiteturais e An√°lise de Performance

### 1. O Custo Oculto do `substring()` e Aloca√ß√£o de Objetos

Uma das principais frentes de otimiza√ß√£o foi o m√©todo de parsing. Inicialmente, avaliamos um parser manual utilizando `substring()` para extrair cada token.

* **O Problema:** O uso extensivo de `line.substring(start, i)` dentro de um loop para 5.2 milh√µes de linhas gera uma press√£o imensa no Garbage Collector (GC). Cada chamada cria um novo objeto `String` na Heap.
* **A Solu√ß√£o:** Evolu√≠mos para um modelo onde priorizamos o tratamento direto de `byte[]` sempre que poss√≠vel, reduzindo a cria√ß√£o de objetos tempor√°rios e mantendo a CPU focada no envio de dados, n√£o na limpeza de mem√≥ria.

### 2. `byte[]` vs. Serializa√ß√£o Bin√°ria (Pseudo-Avro)

Comparamos o envio de dados como `byte[]` contra uma simula√ß√£o de **Avro (bin√°rio)**.

* **Resultado:** Em ambiente **localhost**, o custo de CPU para converter tipos (ex: `Double.parseDouble()`) via c√≥digo Java superou o ganho de economia de rede. A abordagem de bytes brutos provou-se o "teto" de performance local, atingindo o pico de **361k rec/sec**.

### 3. Concorr√™ncia e Threading: O Paradoxo do Paralelismo

Testamos o impacto de `parallelStream()` e Virtual Threads (Java 21).

* **An√°lise:** Para um parser leve, o modo **sequencial** superou o paralelo. Isso ocorreu devido √† redu√ß√£o de conten√ß√£o de locks no `RecordAccumulator` do Kafka Producer e √† elimina√ß√£o do overhead de troca de contexto, permitindo que um √∫nico n√∫cleo de CPU processasse o arquivo de forma linear e ininterrupta.

---

## ‚öôÔ∏è Tuning do Kafka Producer

As configura√ß√µes abaixo foram refinadas para estabilizar o throughput m√°ximo:

| Propriedade | Valor | Motiva√ß√£o T√©cnica |
| :--- | :--- | :--- |
| `batch-size` | `524288` (512KB) | Maximizar o agrupamento de registros por pacote TCP. |
| `linger.ms` | `100` | Garante que o lote seja disparado por tamanho e n√£o por tempo. |
| `compression.type` | `lz4` | Melhor equil√≠brio entre redu√ß√£o de payload e baixo custo de CPU. |
| `buffer.memory` | `134217728` (128MB) | Margem para evitar backpressure durante picos de envio. |

---

## ‚öñÔ∏è Vis√£o S√™nior: Localhost vs. Ambiente de Nuvem

Este benchmark revela trade-offs essenciais para decis√µes de arquitetura em grandes corpora√ß√µes (como Accenture ou Magalu):

1. **Gargalo de CPU vs. Rede:** No localhost, o objetivo √© reduzir o processamento do Java (CPU-Bound). Na nuvem, o objetivo seria reduzir o tamanho da mensagem (I/O-Bound) via Avro para economizar custos de transfer√™ncia de dados (*egress*).
2. **Efici√™ncia de Mem√≥ria:** O custo de aloca√ß√£o de Strings (via `substring`) √© aceit√°vel em aplica√ß√µes de baixa carga, mas torna-se proibitivo em pipelines de Big Data, onde o processamento orientado a bytes √© a norma.
3. **Escalabilidade:** Escalabilidade da Ingest√£o: Enquanto o modo sequencial venceu localmente (devido ao baixo overhead), em um cen√°rio de nuvem a ingest√£o escalaria atrav√©s do aumento do n√∫mero de parti√ß√µes do t√≥pico e da execu√ß√£o de m√∫ltiplas inst√¢ncias do Producer em paralelo (ex: em um cluster Kubernetes). Isso permitiria distribuir a carga de escrita entre diferentes brokers, superando o limite de vaz√£o de uma √∫nica CPU ou placa de rede.

---

### Como Rodar

1. Certifique-se de ter um broker Kafka em `localhost:9092`.
2. Configure o t√≥pico com **12 parti√ß√µes** para performance m√°xima.
3. O arquivo `books_large.csv` deve estar na raiz ou selecione outro csv.
4. Execute `IngestionBenchmark.java`.
